group_by(island) %>%
nest()
# Or each island separately
with(P, walk2(island, data, function(island, P) {
# Pick the colors for the current PCs found significant on this island
curr_colors <- wpc_colors[unique(P$variable)]
# Distances at which significant differences are detected
P %>%
PLOTFUN() +
scale_fill_manual(values = curr_colors)
figname <- sprintf("%s/site_comparisons_%s.png", saveto, island)
ggsave(figname, width = 4, height = 2, dpi = 300)
# Phenotypic versus geographical distances
P %>%
PLOTFUN2() +
scale_fill_manual(values = curr_colors)
figname <- sprintf("%s/site_comparisons2_%s.png", saveto, island)
ggsave(figname, width = 4, height = 3, dpi = 300)
}))
## ---------------------------
##
## Script name: tables.R
##
## Purpose of script:
##
## This script loads relevant tables from the results and
## turns them into nice-looking LaTeX tables
##
## Author: Raphael Scherrer
##
## Date Created: 2021-04-05
##
## Copyright (c) Raphael Scherrer, 2021
##
## Email:
## r.scherrer@rug.nl
## raphael.scherrer@evobio.eu
## raph.rjfs@hotmail.fr
##
## ---------------------------
rm(list = ls())
library(tidyverse)
library(knitr)
library(kableExtra)
#### 0. Accessory functions ####
# Function to add a significance column with asterisk symbols to a tibble
mutate_signif <- function(
D, col = "pvalue", levels = c(0.05, 0.01, 0.001), dropname = TRUE
) {
D <- D %>%
mutate(
.signif = ifelse(get(col) < levels[1], "*", ""),
.signif = ifelse(get(col) < levels[2], "**", .signif),
.signif = ifelse(get(col) < levels[3], "***", .signif)
)
if (dropname) D <- D %>% rename(" " = ".signif")
return(D)
}
# Round and format P-values
round_pvalue <- function(pvalue, digits = 4) {
threshold <- 1 / 10^digits
template <- paste0("%.", sprintf("%sf", digits))
label <- sprintf(paste("<", template), threshold, digits)
rounded <- sprintf(template, round(pvalue, digits), digits)
ifelse(pvalue < threshold, label, rounded)
}
#### 1. Random forest table ####
# Random forest results
read_csv("results/group_comparisons/machine_learning/PC/randomforest/summary.csv") %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 4)) %>%
kable(
"latex",
col.names = c("Island", "$N$", "Score", "$P$", ""),
digits = c(0, 0, 3, 0, 0),
align = "lrrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
) %>%
cat(file = "ms/tables/randomforests.tex")
#### 2. LDA table ####
# LDA results
read_csv("results/group_comparisons/machine_learning/PC/lda/summary.csv") %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 4)) %>%
kable(
"latex",
col.names = c(
"Island", "$N$", "Score", "$P$", ""
),
digits = c(0, 0, 3, 0, 0),
align = "lrrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
) %>%
cat(file = "ms/tables/ldas.tex")
#### 3. SVM table ####
# SVM results
read_csv("results/group_comparisons/machine_learning/PC/ksvm/summary.csv") %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 4)) %>%
kable(
"latex",
col.names = c(
"Island", "$N$", "Score", "$P$", ""
),
digits = c(0, 0, 3, 0, 0),
align = "lrrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
) %>%
cat(file = "ms/tables/ksvms.tex")
#### 4. ANOVA table ####
# ANOVA table
read_csv("results/group_comparisons/anovas.csv") %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 4)) %>%
kable(
"latex",
col.names = c(
"Island", "Variable", "AICc", "$\\Delta$AICc", "AICw", "Model",
"Log-lik.", "$\\chi^2$", "df", "$P$", ""
),
digits = c(0, 0, 2, 2, 3, 0, 2, 2, 0, 0, 0),
align = "llrrrlrrrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
) %>%
cat(file = "ms/tables/anova.tex")
#### 5. Spatial autocorrelation tables ####
# Mantel's test of spatial autocorrelation
read_csv("results/spatial_correlation/mantel_test.csv") %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 3)) %>%
kable(
"latex",
col.names = c(
"Island", "$\\rho$", "$P$", ""
),
digits = c(0, 3, 0, 0),
align = "lrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
) %>%
cat(file = "ms/tables/mantel.tex")
# Spatial autocorrelation (custom permutation test)
read_csv("results/spatial_correlation/spatial_correlation.csv") %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 3)) %>%
kable(
"latex",
col.names = c(
"Island", "$\\rho$", "$P$", ""
),
digits = c(0, 3, 0, 0),
align = "lrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
) %>%
cat(file = "ms/tables/autocorrelation.tex")
#### 6. Sample size table ####
# Sample sizes
read_csv("metadata/counts.csv") %>%
rename(" " = "island") %>%
kable(
"latex",
booktabs = TRUE,
linesep = ""
) %>%
cat(file = "ms/tables/counts.tex")
#### 7. Site metadata table ####
# Site metadata
read_csv("metadata/sites.csv") %>%
kable(
"latex",
col.names = c(
"Island", "Longitude", "Latitude", "Habitat", paste0("PC", 1:4)
),
digits = c(0, 1, 1, 0, 3, 3, 3, 3),
booktabs = TRUE,
linesep = ""
) %>%
cat(file = "ms/tables/sites.tex")
#### 8. PCA table ####
# PCA explained variance
read_csv("results/pc_expvars/pc_expvars.csv") %>%
kable(
"latex",
col.names = c(
"Island", "Total", paste0("PC", 1:4)
),
digits = c(0, 3, 3, 3, 3, 3),
booktabs = TRUE,
linesep = ""
) %>%
cat(file = "ms/tables/pcavariances.tex")
#### 9. Multivariate normality table ####
# Tests of multivariate normality
read_csv("results/assumptions/multinorm.csv") %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 4)) %>%
kable(
"latex",
col.names = c(
"Island", "Habitat", "Outliers", "$HZ$", "$P$", ""
),
digits = c(0, 0, 0, 3, 0, 0),
align = "llrrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
) %>%
cat(file = "ms/tables/multinorm.tex")
#### 10. Normality table ####
# Univariate normality
read_csv("results/assumptions/uninorm.csv") %>%
mutate_signif(col = "padj") %>%
mutate(padj = round_pvalue(padj, digits = 4)) %>%
kable(
"latex",
col.names = c(
"Island", "Variable", "$W$", "$P$", "$P_{adj}$", ""
),
digits = c(0, 0, 3, 4, 0, 0),
align = "llrrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
) %>%
cat(file = "ms/tables/normality.tex")
#### 11. Kruskal-Wallis table ####
# Kruskal-Wallis tests
read_csv("results/group_comparisons/kruskalwallis.csv") %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 4)) %>%
kable(
"latex",
col.names = c(
"Island", "Variable", "$\\chi^2$", "df", "$P$", ""
),
digits = c(0, 0, 2, 0, 0, 0),
align = "llrrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
) %>%
cat(file = "ms/tables/kruskal.tex")
# Tests of multivariate normality
read_csv("results/assumptions/multinorm.csv") %>%
arrange(habitat, island) %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 4)) %>%
kable(
"latex",
col.names = c(
"Island", "Habitat", "Outliers", "$HZ$", "$P$", ""
),
digits = c(0, 0, 0, 3, 0, 0),
align = "llrrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
) %>%
cat(file = "ms/tables/multinorm.tex")
read_csv("results/assumptions/multinorm.csv") %>%
arrange(habitat, island) %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 4)) %>%
kable(
"latex",
col.names = c(
"Island", "Habitat", "Outliers", "$HZ$", "$P$", ""
),
digits = c(0, 0, 0, 3, 0, 0),
align = "llrrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
)
read_csv("results/assumptions/multinorm.csv") %>%
arrange(island, habitat) %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 4)) %>%
kable(
"latex",
col.names = c(
"Island", "Habitat", "Outliers", "$HZ$", "$P$", ""
),
digits = c(0, 0, 0, 3, 0, 0),
align = "llrrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
)
# Tests of multivariate normality
read_csv("results/assumptions/multinorm.csv") %>%
arrange(island, habitat) %>%
mutate_signif() %>%
mutate(pvalue = round_pvalue(pvalue, digits = 4)) %>%
kable(
"latex",
col.names = c(
"Island", "Habitat", "Outliers", "$HZ$", "$P$", ""
),
digits = c(0, 0, 0, 3, 0, 0),
align = "llrrrl",
booktabs = TRUE,
linesep = "",
escape = FALSE
) %>%
cat(file = "ms/tables/multinorm.tex")
library(tidyverse)
rm(list = ls())
data <- read_csv("metadata/sites.csv")
data
filter(data, island == "Abaco")
x <- filter(data, island == "Abaco")
i <- seq(nrow(x) - 1)
i
ii <- seq(nrow(x) - 1)
ii
n <- nrow(x)
a <- 0
ii <- jj <- rep(0, n * (n - 1) / 2)
for (i in seq(n - 1)) {
for (j in i:n) {
a <- a + 1
ii[a] <- i
jj[a] <- j
}
}
ii
jj
ii == jj
ii != jj
kk <- ii != jj
ii <- ii[kk]
jj <- jj[kk]
ii
jj
x
library(geosphere)
?distm
i <- 1
j <- 2
distm(c(x$longitude[i], x$latitude[i]), c(x$longitude[j], x$latitude[j]))
matrix(c(x$longitude[ii], x$latitude[ii]), ncol = 2)
matrix(c(x$longitude[jj], x$latitude[jj]), ncol = 2)
distm(
matrix(c(x$longitude[ii], x$latitude[ii]), ncol = 2),
matrix(c(x$longitude[jj], x$latitude[jj]), ncol = 2)
)
ii
jj
distm(
matrix(c(x$longitude[ii], x$latitude[ii]), ncol = 2)
)
distm(matrix(c(x$longitude, x$latitude), ncol = 2))
distm(matrix(c(x$longitude, x$latitude), ncol = 2), fun = distGeo)
upper(distm(matrix(c(x$longitude, x$latitude), ncol = 2), fun = distGeo))
upper.tri(distm(matrix(c(x$longitude, x$latitude), ncol = 2), fun = distGeo))
y <- distm(matrix(c(x$longitude, x$latitude), ncol = 2), fun = distGeo)
y[upper.tri(y)]
median(y[upper.tri(y)])
data
x <- filter(data, island == "Abaco")
data %>%
group_by(island) %>%
nest() %>%
mutate(dist = map(data, ~ with(.x, distm(matrix(c(longitude, latitude), ncol = 2), fun = distGeo))))
data %>%
group_by(island) %>%
nest() %>%
mutate(dist = map(data, function(data) {
y <- with(.x, distm(matrix(c(longitude, latitude), ncol = 2), fun = distGeo))
y[upper.tri(y)]
}))
data %>%
group_by(island) %>%
nest() %>%
mutate(dist = map(data, function(data) {
y <- with(data, distm(matrix(c(longitude, latitude), ncol = 2), fun = distGeo))
y[upper.tri(y)]
}))
data %>%
group_by(island) %>%
nest() %>%
mutate(dist = map(data, function(data) {
y <- with(data, distm(matrix(c(longitude, latitude), ncol = 2), fun = distGeo))
y[upper.tri(y)]
})) %>%
select(-data) %>%
unnest(dist)
data %>%
group_by(island) %>%
nest() %>%
mutate(dist = map(data, function(data) {
y <- with(data, distm(matrix(c(longitude, latitude), ncol = 2), fun = distGeo))
y[upper.tri(y)]
})) %>%
select(-data) %>%
unnest(dist) %>%
group_by(island) %>%
summarize(median = median(dist))
data %>%
group_by(island) %>%
nest() %>%
mutate(dist = map(data, function(data) {
y <- with(data, distm(matrix(c(longitude, latitude), ncol = 2), fun = distGeo))
y[upper.tri(y)]
})) %>%
select(-data) %>%
unnest(dist) %>%
select(dist) %>%
median
data %>%
group_by(island) %>%
nest() %>%
mutate(dist = map(data, function(data) {
y <- with(data, distm(matrix(c(longitude, latitude), ncol = 2), fun = distGeo))
y[upper.tri(y)]
})) %>%
select(-data) %>%
unnest(dist) %>%
select(dist) %>%
summarize(median = median(dist))
data %>%
group_by(island) %>%
nest() %>%
mutate(dist = map(data, function(data) {
y <- with(data, distm(matrix(c(longitude, latitude), ncol = 2), fun = distGeo))
y[upper.tri(y)]
})) %>%
select(-data) %>%
unnest(dist) %>%
ungroup() %>%
select(dist) %>%
summarize(median = median(dist))
data %>%
group_by(island) %>%
nest() %>%
mutate(dist = map(data, function(data) {
y <- with(data, distm(matrix(c(longitude, latitude), ncol = 2), fun = distGeo))
y[upper.tri(y)]
})) %>%
select(-data) %>%
unnest(dist) %>%
ungroup() %>%
select(dist) %>%
summarize(median = median(dist), below50 = sum(dist < 50000) / n())
rm(list = ls())
library(tidyverse)
library(ggridges) # ridge plots
library(broom) # tidy statistical tables
library(heplots) # Box M test
library(MVN) # multivariate normality
library(assertthat) # assertions within functions
library(rminer) # machine learning
library(geosphere) # geographical distances
library(MuMIn) # AICc
library(nlme) # univariate ANOVAs
library(PMCMRplus) # posthoc tests
library(RColorBrewer) # color palette
library(pairwiseAdonis) # posthoc PERMANOVA
library(scales) # color palette
library(vegan) # PERMANOVA
library(ape) # Mantel test
mavg <- function(x) Reduce('+', x) / length(x)
#### 1. Set-up ####
# Set plotting theme
theme_set(theme_classic())
# Graphical parameters
island_colors <- brewer.pal(8, "Set2")
island_colors <- c(island_colors, "darkgreen")
habitat_colors <- c("goldenrod", "forestgreen", "mediumseagreen")
# Global settings
pc_names <- paste0("PC", 1:4)
wpc_names <- paste0("w", pc_names)
wl <- 300:700
wl_names <- paste0("wl", wl)
# Whether to load machines already fitted to whole spectrum data
# (instead of rerunning the very lengthy classification)
read_fitted <- TRUE
# Read the data
D <- read_csv("data/reflectance3.csv")
D <- D %>% select(-fieldtag, -code, -locale, -sex, -notes, -spot, -specimen) %>% mutate(id = seq(n()))
# Useful things to keep in mind
island_names <- unique(D$island)
habitat_names <- unique(D$habitat)
# Perform a PCA first because wavelengths are highly correlated
PCA <- prcomp(D[, wl_names], center = TRUE, scale = TRUE)
# How many PCs to retain?
cumsum(PCA$sdev / sum(PCA$sdev))
# Retain explained variance
expvars <- PCA$sdev[1:4] / sum(PCA$sdev)
# With four PCs we explain more than 90% of the variance
PCs <- PCA$x[, 1:4]
# Scale the principal components to unit variance (they are centered by constr)
PCs <- scale(PCs, scale = TRUE)
# Attach the matrix of principal components to the dataset
D <- cbind(D, PCs)
# Now we use a two-way MANOVA to ask about differences
summary(manova(PCs ~ island * habitat, data = D))
set.seed(42)
# PERMANOVA
adonis(dist(PCs) ~ island * habitat, data = D, permutations = 1000)
